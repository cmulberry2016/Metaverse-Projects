# Metaverse-Projects
Portfolio showcase of my augmented and mixed reality solutions

![Creator Pic](https://user-images.githubusercontent.com/23661772/168881664-a73703f6-54a8-4d3b-972d-c3a3f1932c24.png)

<details><summary>PROXIMITY NETWORKING TOOL ü§ù ("Spatial Search")</summary>
<p>
    
## **The Problem**
   
Current social networking applications lack the ability for in-person connection.
    
<img width="1728" alt="Isolation" src="https://user-images.githubusercontent.com/23661772/169326836-fc7d67cf-92e0-4dcf-a261-b358286a66c8.png">


## **The Challenge**

Create a profile matching system that connects profiles based on shared physical location within a social distance.

## The Solution

Camera Based Search Engine for Location-Based Augmented Reality Networking
    
<img width="2744" alt="Vibed Proximity Matching System" src="https://user-images.githubusercontent.com/23661772/169327830-44e2bc02-7e09-4cd6-9fac-dccc51f370ab.png">

System Stack Used:
    
- Networking with **[Lightship Multiplayer API](https://lightship.dev/docs/ardk/multiplayer/index.html#multiplayer)**
- Interfacing through **[UnityUI](https://docs.unity3d.com/Packages/com.unity.ugui@1.0/manual/script-InputField.html)**
- Matching with **[Firebase Query](https://firebase.google.com/docs/reference/unity/class/firebase/database/query)**
- Scripted in **[C#](https://docs.microsoft.com/en-us/dotnet/csharp/)**

## **The Results**
    
Profile matching in < 0.4 seconds
    
![Proximity Networking Demo](https://user-images.githubusercontent.com/23661772/169137488-2851c9c9-717a-4240-9406-874080a3c0db.gif)
    
## The Opportunity

Add support for consumer Mixed Reality Glasses (Nreal Light / Lightship Glass / Snap Lenses)

</p>
</details>

<details><summary>VISUAL SCRIPTING TOOL üëÅÔ∏è ("Reality Creator")</summary>
<p>

## **The Problem**
   
Managing implicit object relationships is difficult when programming behavioral interactions
    
![Unity Editor](https://user-images.githubusercontent.com/23661772/169331758-0e69ede4-6b78-4ac1-af11-d4b228ccb61a.png)

## **The Challenge**

Create a visual scripting engine for mixed reality application development 

## The Solution

System Stack Used:

- Component Connections with **[Messages API](https://docs.enklu.com/docs/API/Messages)**
- Interfacing through **[Hands API](https://docs.enklu.com/docs/API/Hand)** and **[Gaze API](https://enklu.notion.site/Gaze-Preview-f30d65b03da24c06938d51a83a25585f)**
- Scripted in **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**

## **The Results**

Interactions can be built and connected without the need for keyboard programming 
    
![Editor Design](https://user-images.githubusercontent.com/23661772/169062686-04958745-8e30-4464-b7e6-d115f16be0b4.gif)

## The Opportunity

Add support for grouping ("nested") for behavioral interactions

</p>
</details>

<details><summary>PRODUCT VISUALIZATION TOOL üîé ("PCB Explorer")</summary>
<p>
    
![PCB Explorer](https://user-images.githubusercontent.com/23661772/169063472-36a70e46-2d60-43ef-9e99-2a0823003a00.gif)


## **The Problem**
   
Understanding how complex implicit system relationships are configured are difficult to understand without breaking down to individual components.

## **The Challenge**

Disassembling meshed prefabs from industrial design files and adding tween movement animations + descriptions interface windows.

## The Solution

System Stack Used:

- Input with [X]
- Interfacing with [Y]
- Inferencing through **[CoreML Model](https://developer.apple.com/machine-learning/models/)**
- Training with **[Custom Vision](https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/#overview)**
- Programming Languages: **[C++](https://www.cplusplus.com/reference/)**,  **[C#](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**, **[Swift](https://developer.apple.com/swift/)**
- Hardware: Hololens 2

## **The Results**

Comprehension Rate: 80%

## The Opportunity

How can AR HMD operating systems be used to search real-world objects in the real world environment?

</p>
</details>


<details><summary>ASSEMBLY TRAINING ASSISTANT TOOL üîß ("EVAssemblySim")</summary>
<p>
    
![Assembly Simulation](https://user-images.githubusercontent.com/23661772/169124090-cfec29b5-a17b-4043-a497-7148b8a18684.gif)
    
## **The Problem**
   
Understanding how complex implicit system relationships are configured are difficult to understand without breaking down to individual components.

## **The Challenge**

Disassembling meshed prefabs from industrial design files and adding tween movement animations + descriptions interface windows.

## The Solution!

System Stack Used:

- Input with [X]
- Interfacing with [Y]
- Inferencing through **[CoreML Model](https://developer.apple.com/machine-learning/models/)**
- Training with **[Custom Vision](https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/#overview)**
- Programming Languages: **[C++](https://www.cplusplus.com/reference/)**,  **[C#](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**, **[Swift](https://developer.apple.com/swift/)**
- Hardware: Hololens 2

## **The Results**

Comprehension Rate: 80%

## The Opportunity

How can AR HMD operating systems be used to search real-world objects in the real world environment?

</p>
</details>


<details><summary>CELL VISUALIZATION ASSISTANT TOOL ü¶† ("Sars-Cov-2 Explorer")</summary>
<p>
    
![NIH Demo](https://user-images.githubusercontent.com/23661772/169129398-445aefc2-115e-4122-9601-f4d58433fb56.gif)

    
## **The Problem**
   
Understanding how complex implicit system relationships are configured are difficult to understand without breaking down to individual components.

## **The Challenge**

Disassembling meshed prefabs from industrial design files and adding tween movement animations + descriptions interface windows.

## The Solution!

System Stack Used:

- Input with [X]
- Interfacing with [Y]
- Inferencing through **[CoreML Model](https://developer.apple.com/machine-learning/models/)**
- Training with **[Custom Vision](https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/#overview)**
- Programming Languages: **[C++](https://www.cplusplus.com/reference/)**,  **[C#](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**, **[Swift](https://developer.apple.com/swift/)**
- Hardware: Hololens 2

## **The Results**

Comprehension Rate: 80%

## The Opportunity

How can AR HMD operating systems be used to search real-world objects in the real world environment?

</p>
</details>

<details><summary>EPIPEN TRAINING ASSISTANT TOOL üíâ ("EpipenSim")</summary>
<p>
    
![Epipen](https://user-images.githubusercontent.com/23661772/169313130-42c3e8ee-e6ac-4005-ac9e-bc3321147573.gif)
    
## **The Problem**
   
Understanding how complex implicit system relationships are configured are difficult to understand without breaking down to individual components.

## **The Challenge**

Disassembling meshed prefabs from industrial design files and adding tween movement animations + descriptions interface windows.

## The Solution!

System Stack Used:

- Input with [X]
- Interfacing with [Y]
- Inferencing through **[CoreML Model](https://developer.apple.com/machine-learning/models/)**
- Training with **[Custom Vision](https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/#overview)**
- Programming Languages: **[C++](https://www.cplusplus.com/reference/)**,  **[C#](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**, **[Swift](https://developer.apple.com/swift/)**
- Hardware: Hololens 2

## **The Results**

Comprehension Rate: 80%

## The Opportunity

How can AR HMD operating systems be used to search real-world objects in the real world environment?

</p>
</details>

</p>
</details>

<details><summary>BRAIN SCAN ASSISTANT TOOL üß† ("MRI Visualizer")</summary>
<p>
    
![Brain Scan Demo](https://user-images.githubusercontent.com/23661772/169314421-77c9fa87-4894-400e-a918-11a16cd8cfd3.gif)

    
## **The Problem**
   
Understanding how complex implicit system relationships are configured are difficult to understand without breaking down to individual components.

## **The Challenge**

Disassembling meshed prefabs from industrial design files and adding tween movement animations + descriptions interface windows.

## The Solution!

System Stack Used:

- Input with [X]
- Interfacing with [Y]
- Inferencing through **[CoreML Model](https://developer.apple.com/machine-learning/models/)**
- Training with **[Custom Vision](https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/#overview)**
- Programming Languages: **[C++](https://www.cplusplus.com/reference/)**,  **[C#](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**, **[Swift](https://developer.apple.com/swift/)**
- Hardware: Hololens 2

## **The Results**

Comprehension Rate: 80%

## The Opportunity

How can AR HMD operating systems be used to search real-world objects in the real world environment?

</p>
</details>
