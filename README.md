# Metaverse-Projects
Portfolio showcase of my augmented and mixed reality solutions

![Creator Pic](https://user-images.githubusercontent.com/23661772/168881664-a73703f6-54a8-4d3b-972d-c3a3f1932c24.png)

<details><summary>PROXIMITY NETWORKING TOOL ü§ù </summary>
<p>
    
## **The Problem**
   
Current social networking applications lack the ability for in-person connection.
    
<img width="1728" alt="Isolation" src="https://user-images.githubusercontent.com/23661772/169326836-fc7d67cf-92e0-4dcf-a261-b358286a66c8.png">

## **The Challenge**

Create a profile matching system that connects profiles based on shared physical location within a social distance.

## The Solution

Camera Based Search Engine for Location-Based Augmented Reality Networking

System Stack Used:
    
- Networking with **[Lightship Multiplayer API](https://lightship.dev/docs/ardk/multiplayer/index.html#multiplayer)**
- Interfacing through **[UnityUI](https://docs.unity3d.com/Packages/com.unity.ugui@1.0/manual/script-InputField.html)**
- Matching with **[Firebase Query](https://firebase.google.com/docs/reference/unity/class/firebase/database/query)**
- Scripted in **[C#](https://docs.microsoft.com/en-us/dotnet/csharp/)**
- Hardware Supported: iPhone + iPad

## **The Results**
    
Profile matching in < 0.4 seconds
    
![Proximity Networking Demo](https://user-images.githubusercontent.com/23661772/169137488-2851c9c9-717a-4240-9406-874080a3c0db.gif)
    
## The Opportunity

Add support for consumer Mixed Reality Glasses (Nreal Light / Lightship Glass / Snap Lenses)

</p>
</details>

<details><summary>VISUAL SCRIPTING TOOL üëÅÔ∏è </summary>
<p>

## **The Problem**
   
Managing implicit object relationships is difficult when programming behavioral interactions
    
![Unity Editor](https://user-images.githubusercontent.com/23661772/169331758-0e69ede4-6b78-4ac1-af11-d4b228ccb61a.png)

## **The Challenge**

Create a visual scripting engine for mixed reality application development 

## The Solution

System Stack Used:

- Component Connections with **[Messages API](https://docs.enklu.com/docs/API/Messages)**
- Interfacing through **[Hands API](https://docs.enklu.com/docs/API/Hand)** and **[Gaze API](https://enklu.notion.site/Gaze-Preview-f30d65b03da24c06938d51a83a25585f)**
- Scripted in **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**
- Hardware Supported: Hololens 2

## **The Results**

Interactions can be built and connected without the need for keyboard programming 
    
![Editor Design](https://user-images.githubusercontent.com/23661772/169062686-04958745-8e30-4464-b7e6-d115f16be0b4.gif)

## The Opportunity

Add support for grouping ("nested") behavioral interactions

</p>
</details>

<details><summary>PRODUCT VISUALIZATION TOOL üîé </summary>
<p>
    
## **The Problem**
   
Understanding how complex system relationships are configured is difficult to understand without breaking down to individual components.
    
![Complex System](https://user-images.githubusercontent.com/23661772/169335713-84065c82-c07b-4c50-8959-47cc2bfad6ce.jpeg)

## **The Challenge**

Create a visualization engine for disassembled meshed prefabs

## The Solution

System Stack Used:

- Prefab Animation with **[Tween API](https://enklu.notion.site/Tween-cc9d594d6c2548e8a16870902e6e4dc4)**
- Interfacing with **[Touch API](https://enklu.notion.site/Touch-d73ef1eb42c84ac284b99d7d68b912d4)** and **[Timers API](https://enklu.notion.site/Timers-612d9f808504469495cfd1a566cd3f25)**
- Learning Management with **[Score API](https://enklu.notion.site/Score-Preview-b8a4fe64c5724d0196e01ea1ebfb2ef6)**
- Scripted in **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**
- Hardware Supported: Hololens 2

## **The Results**

Comprehension Rate: 80%

![PCB Explorer](https://user-images.githubusercontent.com/23661772/169063472-36a70e46-2d60-43ef-9e99-2a0823003a00.gif)

## The Opportunity

Add support for automatic component naming through file extension formatting 
    
</p>
</details>


<details><summary>ASSEMBLY TRAINING ASSISTANT TOOL üîß </summary>
<p>
    
## **The Problem**

Rework is expensive for factory line technicians without a strong understanding of the machine composition and configuration
    
![Factory Worker](https://user-images.githubusercontent.com/23661772/169346614-b264a464-60c9-4e05-8cfd-d59a0667f292.jpeg)

## **The Challenge**

Create an vechicle assembly guide that safely walks line technicians through machine assembly 

## The Solution

System Stack Used:

- Interfacing through **[Hands API](https://docs.enklu.com/docs/API/Hand)** and **[Gaze API](https://enklu.notion.site/Gaze-Preview-f30d65b03da24c06938d51a83a25585f)**
- Voice Assistance with **[SAI API](https://enklu.notion.site/App-7a613b15a29840a0a882761bf5e940ab#cb070b7f690b45f69ace511078e9ee83)**
- Learning Management with **[Score API](https://enklu.notion.site/Score-Preview-b8a4fe64c5724d0196e01ea1ebfb2ef6)**
- Scripted in **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**
- Hardware: Hololens 2

## **The Results**

Error Rate: < 10%
    
![Assembly Simulation](https://user-images.githubusercontent.com/23661772/169124090-cfec29b5-a17b-4043-a497-7148b8a18684.gif)

## The Opportunity

Add support for vehicle maintenance troubleshooting

</p>
</details>


<details><summary>CELL VISUALIZATION ASSISTANT TOOL ü¶† </summary>
<p>
    
![NIH Demo](https://user-images.githubusercontent.com/23661772/169129398-445aefc2-115e-4122-9601-f4d58433fb56.gif)

    
## **The Problem**
   
Understanding how complex implicit system relationships are configured are difficult to understand without breaking down to individual components.

## **The Challenge**

Disassembling meshed prefabs from industrial design files and adding tween movement animations + descriptions interface windows.

## The Solution!

System Stack Used:

- Input with [X]
- Interfacing with [Y]
- Inferencing through **[CoreML Model](https://developer.apple.com/machine-learning/models/)**
- Training with **[Custom Vision](https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/#overview)**
- Programming Languages: **[C++](https://www.cplusplus.com/reference/)**,  **[C#](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**, **[Swift](https://developer.apple.com/swift/)**
- Hardware: Hololens 2

## **The Results**

Comprehension Rate: 80%

## The Opportunity

How can AR HMD operating systems be used to search real-world objects in the real world environment?

</p>
</details>

<details><summary>EPIPEN TRAINING ASSISTANT TOOL üíâ </summary>
<p>
    
![Epipen](https://user-images.githubusercontent.com/23661772/169313130-42c3e8ee-e6ac-4005-ac9e-bc3321147573.gif)
    
## **The Problem**
   
Understanding how complex implicit system relationships are configured are difficult to understand without breaking down to individual components.

## **The Challenge**

Disassembling meshed prefabs from industrial design files and adding tween movement animations + descriptions interface windows.

## The Solution!

System Stack Used:

- Input with [X]
- Interfacing with [Y]
- Inferencing through **[CoreML Model](https://developer.apple.com/machine-learning/models/)**
- Training with **[Custom Vision](https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/#overview)**
- Programming Languages: **[C++](https://www.cplusplus.com/reference/)**,  **[C#](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**, **[Swift](https://developer.apple.com/swift/)**
- Hardware: Hololens 2

## **The Results**

Comprehension Rate: 80%

## The Opportunity

How can AR HMD operating systems be used to search real-world objects in the real world environment?

</p>
</details>

</p>
</details>

<details><summary>BRAIN SCAN ASSISTANT TOOL üß† </summary>
<p>
    
![Brain Scan Demo](https://user-images.githubusercontent.com/23661772/169314421-77c9fa87-4894-400e-a918-11a16cd8cfd3.gif)

    
## **The Problem**
   
Understanding how complex implicit system relationships are configured are difficult to understand without breaking down to individual components.

## **The Challenge**

Disassembling meshed prefabs from industrial design files and adding tween movement animations + descriptions interface windows.

## The Solution!

System Stack Used:

- Input with [X]
- Interfacing with [Y]
- Inferencing through **[CoreML Model](https://developer.apple.com/machine-learning/models/)**
- Training with **[Custom Vision](https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/#overview)**
- Programming Languages: **[C++](https://www.cplusplus.com/reference/)**,  **[C#](https://developer.mozilla.org/en-US/docs/Web/JavaScript)**, **[Swift](https://developer.apple.com/swift/)**
- Hardware: Hololens 2

## **The Results**

Comprehension Rate: 80%

## The Opportunity

How can AR HMD operating systems be used to search real-world objects in the real world environment?

</p>
</details>
